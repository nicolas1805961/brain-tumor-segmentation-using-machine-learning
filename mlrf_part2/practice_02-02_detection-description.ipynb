{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPITA 2020 MLRF practice_02-02_detection-description v2020-04-30_002250 by Joseph CHAZALON\n",
    "\n",
    "<div style=\"overflow: auto; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"Creative Commons License\" src='img/CC-BY-4.0.png' style='float: left; margin-right: 20px'>\n",
    "    \n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 02 part 02: Keypoint detection and description\n",
    "The goal of this second part is to build a framework which will compare pre-selected bubbles (using color histograms, this will be integrated in the next part) in a way more robust than template matching.\n",
    "\n",
    "The issue with template matching is that we need to slide the template over the test image, eventually producing supurious correlations (over flat regions for instance).\n",
    "![template matching](img/template-matching.jpg)\n",
    "\n",
    "What we will do instead is to find stable points within texture patterns, and compare the region centered around those points.\n",
    "![poi matching](img/poi-matching.jpg)\n",
    "\n",
    "\n",
    "This part contains the following steps:\n",
    "1. Manually detect Harris corners.\n",
    "2. Extract descriptors around those keypoints.\n",
    "3. Precompute the keypoints and their descriptors for all bubbles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Harris corner detector\n",
    "We will implement a Harris corner detector now.\n",
    "\n",
    "### 1.1. Mathematical background and how we derive what we will compute \n",
    "\n",
    "#### The basic idea\n",
    "A corner is an image patch which exhibits a high difference with itself when translated in any direction, ie where\n",
    "$$(I(x+\\Delta_x,y+\\Delta_y) - I(x,y))^2$$\n",
    "is high, $(\\Delta_x,\\Delta_y)$ being a displacement vector.\n",
    "\n",
    "#### Practical consideration\n",
    "In practice we pool the previous indicator function over a small region $R = [-s,s] \\times [-s,s]$ and \n",
    "we use a weighting function $w(u,v)$ (with $(u,v) \\in R$) to weight the contribution of each displacement to the global sum:\n",
    "$$\n",
    "S(x,y) = \\sum_u \\sum_v w(u,v) \\, \\left( I(x+u+\\Delta_x,y+v+\\Delta_y) - I(x+u,y+v)\\right)^2\n",
    "$$\n",
    "where $u$ and $v$ both take values in $[-s,+s]$ if $s$ is the size of the neighborhood we consider.\n",
    "Usually $w(u,v)$ is either a [box filter](https://en.wikipedia.org/wiki/Box_blur) or a [Gaussian](https://en.wikipedia.org/wiki/Gaussian_function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation trick using precomputed derivatives\n",
    "$I(x+\\Delta_x,y+\\Delta_y)$ can be approximated by a [Taylor expansion](https://en.wikipedia.org/wiki/Taylor_series):\n",
    "$$\n",
    "I(x+\\Delta_x,y+\\Delta_y) \\approx I(x,y) + \\Delta_x \\frac{\\partial I(x,y)}{\\partial x} + \\Delta_y \\frac{\\partial I(x,y)}{\\partial y} + \\cdots\n",
    "$$\n",
    "This allows us to \"simplify\" the original equation, and more important making it faster to compute, thanks to simpler derivatives which can be computed for the whole image:\n",
    "$$\n",
    "S(x,y) \\approx \\sum_u \\sum_v w(u,v) \\left( \\Delta_x \\frac{\\partial I(x+u,y+v)}{\\partial x} + \\Delta_y \\frac{\\partial I(x+u,y+v)}{\\partial y} \\right)^2\n",
    "$$\n",
    "which can be rewritten as:\n",
    "$$\n",
    "S(x,y) \\approx \\sum_u \\sum_v w(u,v) \\left( (\\Delta_x \\frac{\\partial I(x+u,y+v)}{\\partial x})^2 + (\\Delta_y \\frac{\\partial I(x+u,y+v)}{\\partial y})^2 + 2 \\Delta_x \\Delta_y \\frac{\\partial I(x+u,y+v)}{\\partial x} \\frac{\\partial I(x+u,y+v)}{\\partial y} \\right)\n",
    "$$\n",
    "or, using the matrix form which is usually given:\n",
    "$$\n",
    "S(x,y) \\approx \\begin{pmatrix} \\Delta_x & \\Delta_y \\end{pmatrix} A(x,y) \\begin{pmatrix} \\Delta_x \\\\ \\Delta_y \\end{pmatrix},\n",
    "$$\n",
    "where $A(x,y)$ is the [structure tensor](https://en.wikipedia.org/wiki/Structure_tensor):\n",
    "$$\n",
    "A = \\sum_u \\sum_v w(u,v) \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial I^2(x+u,y+v)}{\\partial x} & \\frac{\\partial I(x+u,y+v)}{\\partial x} \\frac{\\partial I(x+u,y+v)}{\\partial y} \\\\\n",
    "\\frac{\\partial I(x+u,y+v)}{\\partial x} \\frac{\\partial I(x+u,y+v)}{\\partial y} & \\frac{\\partial I^2(x+u,y+v)}{\\partial y} \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\langle I_x^2 \\rangle & \\langle I_x I_y \\rangle\\\\\n",
    "\\langle I_x I_y \\rangle & \\langle I_y^2 \\rangle\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where:\n",
    "- $\\langle \\cdots \\rangle$ denotes the windowed summation over $R$;\n",
    "- $I_x$ is the $x$ derivative of $I$;\n",
    "- $I_y$ is the $y$ derivative of $I$.\n",
    "\n",
    "This trick is useful because $I_x$ and $I_y$ can be precomputed very simply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying corners\n",
    "A corner (or in general an interest point) is characterized by a large variation of $S$ in all directions of the vector $\\begin{pmatrix} x & y \\end{pmatrix}$.  By analyzing the eigenvalues of $A$, this characterization can be expressed in the following way: $A$ should have two \"large\" eigenvalues for an interest point.\n",
    "Based on the magnitudes of the eigenvalues, the following inferences can be made based on this argument:\n",
    "- If $\\lambda_1 \\approx 0$ and $\\lambda_2 \\approx 0$ then this pixel $(x,y)$ has no features of interest.\n",
    "- If $\\lambda_1 \\approx 0$ and $\\lambda_2$ has some large positive value, then an edge is found.\n",
    "- If $ \\lambda_1$ and $ \\lambda_2$ have large positive values, then a corner is found.\n",
    "\n",
    "To avoid the computation of the eigenvalues, which used to be expensive, Harris and Stephens instead suggest the\n",
    "following function $M_c$, where $\\kappa$ is a tunable sensitivity parameter:\n",
    "\n",
    "$$\n",
    "M_c = \\lambda_1 \\lambda_2 - \\kappa \\, (\\lambda_1 + \\lambda_2)^2\n",
    "= \\operatorname{det}(A) - \\kappa \\, \\operatorname{trace}^2(A)\n",
    "$$\n",
    "\n",
    "Or, if we prefer to avoid setting the parameter $\\kappa$, we can use Noble's corner measure $M_c'$ which amounts to the harmonic mean of the eigenvalues:\n",
    "$$\n",
    "M_c' = 2 \\frac{\\operatorname{det}(A)}{\\operatorname{trace}(A) + \\epsilon},\n",
    "$$\n",
    "$\\epsilon$ being a small positive constant.\n",
    "\n",
    "\n",
    "$A$ being a 2x2 matrix, we have the following relations:\n",
    "- $\\operatorname{det}(A) = A_{1,1} A_{2,2} - A_{2,1} A_{1,2}$\n",
    "- $\\operatorname{trace}(A) = A_{1,1} + A_{2,2}$\n",
    "\n",
    "Using previous definitions, we obtain:\n",
    "- $\\operatorname{det}(A) = \\langle I_x^2 \\rangle \\langle I_y^2 \\rangle - \\langle I_x I_y \\rangle^2$\n",
    "- $\\operatorname{trace}(A) = \\langle I_x^2 \\rangle + \\langle I_y^2 \\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $I_x$ and $I_y$ in practice\n",
    "A naive way of computing an approximation of $I_x$ (resp. $I_y$) would be to simply compute the difference between pixel value in horizontal (resp. vertical) directions. `np.gradient` would then compute something like:\n",
    "$$I_x(x,y) = I(x,y) - I(x+1,y),$$\n",
    "which produces **spiky results** and lead to **poor performance**.\n",
    "\n",
    "So, in practice we smooth the image before computing the gradients.\n",
    "A common practice is to perform a small Gaussian blur before applying the Sobel operator in both directions, but we can be even more efficient by convolving our image with $G_x$ and $G_y$, two Gaussian derivative kernels with respect to $x$ and $y$!\n",
    "\n",
    "We can relate that to algebraic properties of convolutions:\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\textrm{Sobel} * \\textrm{Gaussian} * \\textrm{Image} &= \\textrm{Gaussian} * \\textrm{Sobel} * \\textrm{Image}\\\\\n",
    "&= (\\textrm{Gaussian} * \\textrm{Sobel}) * \\textrm{Image}\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "**So, to compute $I_x$ or $I_y$, one only needs to convolve $I$ with a Gaussian derivative kernel with respect to $x$ or $y$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harris response, to sum up\n",
    "**In summary, given an image, we can compute the Harris corner response image by simply computing:**\n",
    "- **$I_x$: $I$'s smoothed (interpolated) partial derivative with respect to $x$;**\n",
    "- **$I_y$: $I$'s smoothed (interpolated) partial derivative with respect to $y$;**\n",
    "- **$\\langle I_x^2 \\rangle$: the windowed sum of $I^2_x$;**\n",
    "- **$\\langle I_y^2 \\rangle$: the windowed sum of $I^2_y$;**\n",
    "- **$\\langle I_x I_y \\rangle$: the windowed sum of $I_x I_y$;**\n",
    "- **$\\operatorname{det}(A)$;**\n",
    "- **$\\operatorname{trace}(A)$;**\n",
    "- **$M_c'' = \\frac{\\operatorname{det}(A)}{\\operatorname{trace}(A) + \\epsilon}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Implement the computation of the Harris response\n",
    "Enough math, let's code!\n",
    "We will guide you along the process, so be reassured.\n",
    "\n",
    "After some setup, we will implement the computation of the response image progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate buggy jupyter completion\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "PATH_TO_RESOURCES = \".\"  # FIXME set this to the path of the twinit resource directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Gaussian and Gaussian derivatives\n",
    "A [Gaussian function](https://en.wikipedia.org/wiki/Gaussian_function) is a function of the form:\n",
    "$$\n",
    "f(x) = a e^{-(x-b)^2/(2c^2)}\n",
    "$$\n",
    "The graph of a Gaussian is a characteristic symmetric \"[bell curve](https://en.wikipedia.org/wiki/Normal_distribution)\" shape.\n",
    "The parameter $a$ is the height of the curve's peak, $b$ is the position of the center of the peak and $c$ (the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation)) controls the width of the \"bell\".\n",
    "\n",
    "In our case, we have a two-dimensional signal therefore our function has the form:\n",
    "$$f(x,y) = a \\exp\\left(- \\left(\\frac{(x-x_o)^2}{2\\sigma_X^2} + \\frac{(y-y_o)^2}{2\\sigma_Y^2} \\right)\\right).$$\n",
    "\n",
    "Here the coefficient $a$ is the amplitude, $x_0,y_0$ is the center and $\\sigma_x,\\sigma_y$ are the $x$ and $y$ spreads of the blob.\n",
    "\n",
    "In our case, we will define our Gaussian kernel with respect to the size $s$ of the window $w$.\n",
    "We want to have:\n",
    "- an amplitude ($a$) of $1$;\n",
    "- a center $x_0,y_0$ at the middle of the window: $(0,0)$;\n",
    "- a spread $\\sigma_x,\\sigma_y$ of one third of the size of the window: $(s/3,s/3)$.\n",
    "\n",
    "The derivatives are easy to compute in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Complete the function below to generate a Gaussian kernel.**\n",
    "\n",
    "Tips:\n",
    "- Do no worry about scaling factors for kernels as they will be scaled automatically during the convolution process.\n",
    "- Make sure to check the documentation of [`np.mgrid`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mgrid.html) which generates a grid of coordinates.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me!\n",
    "np.mgrid[-1:1+1,-1:1+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the code of this function\n",
    "def gauss_kernel(size, sizey=None):\n",
    "    \"\"\" Returns a 2D gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    sizey = int(sizey) if sizey is not None else size\n",
    "    y, x = np.mgrid[-size:size+1, -sizey:sizey+1]\n",
    "\n",
    "    # x and y coefficients of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    g = np.ones((size*2+1, sizey*2+1))  # FIXME this is a box filter, adapt it to be a Gaussian\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly display this kernel to check its shape.\n",
    "We are looking for something which looks like this, ie a maximal response at the center of the window, then a smooth decrease toward the borders of the window where we have values close to 0:\n",
    "![Gaussian](img/gaussian_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsize = 5\n",
    "Y,X = np.mgrid[-wsize:wsize+1,-wsize:wsize+1]\n",
    "Z = gauss_kernel(wsize)\n",
    "print(X.shape, Y.shape, Z.shape)\n",
    "# print(Z)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Complete the function below to generate two Gaussian derivative kernels, then plot them.**\n",
    "\n",
    "Tips:\n",
    "- Do no worry about scaling factors for kernels as they will be scaled automatically during the convolution process.\n",
    "- It **really** looks like the previous one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for Gaussian derivatives which look like this:\n",
    "![Gaussian derivatives](img/gaussian_derivatives_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete this function\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\" returns x and y derivatives of a 2D \n",
    "        gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    sizey = int(sizey) if sizey is not None else size\n",
    "    y, x = np.mgrid[-size:size+1, -sizey:sizey+1]\n",
    "\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    gx = np.ones((size*2+1, sizey*2+1))  # FIXME\n",
    "    gy = np.ones((size*2+1, sizey*2+1))  # FIXME\n",
    "\n",
    "    return gx,gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (just run this cell)\n",
    "# Plot gx and gy\n",
    "wsize = 5\n",
    "Y,X = np.mgrid[-wsize:wsize+1,-wsize:wsize+1]\n",
    "Gx, Gy = gauss_derivative_kernels(wsize)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_surface(X, Y, Gx)\n",
    "ax.set_title(\"Gx\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.plot_surface(X, Y, Gy)\n",
    "ax.set_title(\"Gy\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Complete the function below to compute $I_x$ and $I_y$.**\n",
    "\n",
    "Tips:\n",
    "- Use `scipy.signal.convolve` to apply the kernels.\n",
    "- Make sure the target image has the **same** size as the original image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "signal.convolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete this function\n",
    "def gauss_derivatives(im, n, ny=None):\n",
    "    \"\"\" returns x and y derivatives of an image using gaussian \n",
    "        derivative filters of size n. The optional argument \n",
    "        ny allows for a different size in the y direction.\"\"\"\n",
    "\n",
    "    gx,gy = gauss_derivative_kernels(n, sizey=ny)\n",
    "\n",
    "    imx = np.zeros_like(im)  # FIXME\n",
    "    imy = np.zeros_like(im)  # FIXME\n",
    "\n",
    "    return imx,imy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Load some bubble images and show their derivatives.**\n",
    "\n",
    "Tips:\n",
    "- Make sure you compute derivatives on the grayscale image.\n",
    "- A filter of size $3$ will be used lated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Jupyter magic to help you\n",
    "bubble_files = !ls $PATH_TO_RESOURCES/bubbles_200dpi/b*.png | sort\n",
    "bubble_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load some bubbles\n",
    "bubbles = []\n",
    "bubbles_gray = []  # list of bubbles (np.array) in grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (just run this cell)\n",
    "# Display some bubbles and their derivatives\n",
    "\n",
    "# Let us save time\n",
    "def imbgr2rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "num_bb = 5\n",
    "plt.figure(figsize=(8,10))\n",
    "for bb_id in range(num_bb):\n",
    "    bb = bubbles[bb_id]\n",
    "    bb_gray = bubbles_gray[bb_id]\n",
    "    bb_x, bb_y = gauss_derivatives(bb_gray, 3)\n",
    "    plt.subplot(num_bb,3,1+3*bb_id)\n",
    "    plt.imshow(imbgr2rgb(bb))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"$I$: bb_%d\" % bb_id)\n",
    "    plt.subplot(num_bb,3,2+3*bb_id)\n",
    "    plt.imshow(bb_x)\n",
    "    plt.colorbar(shrink=0.5)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"$I_x$\")\n",
    "    plt.subplot(num_bb,3,3+3*bb_id)\n",
    "    plt.imshow(bb_y)\n",
    "    plt.colorbar(shrink=0.75)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"$I_y$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Harris response\n",
    "We can now compute the Harris response of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Compute and show the Harris response for some bubbles.**\n",
    "\n",
    "Tips:\n",
    "- Make sure you compute derivatives on the grayscale image.\n",
    "- A filter of size $3$ is appropriate to compute the derivatives.\n",
    "- A size of $3$ (the \"opening parameter\" ie the size of the area we average the value on) is also appropriate for the Gaussian filter used to perform the weighted sum.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete this function\n",
    "def compute_harris_response(image):\n",
    "    \"\"\" compute the Harris corner detector response function \n",
    "        for each pixel in the image\"\"\"\n",
    "    DERIVATIVE_KERNEL_SIZE = 1\n",
    "    OPENING_SIZE = 1\n",
    "\n",
    "    #derivatives\n",
    "    imx,imy = gauss_derivatives(image, DERIVATIVE_KERNEL_SIZE)\n",
    "\n",
    "    #kernel for weighted sum\n",
    "    gauss = gauss_kernel(OPENING_SIZE) # opening param\n",
    "\n",
    "    #compute components of the structure tensor\n",
    "    Wxx = np.zeros_like(image)  # FIXME\n",
    "    Wxy = np.zeros_like(image)  # FIXME\n",
    "    Wyy = np.zeros_like(image)  # FIXME\n",
    "\n",
    "    #determinant and trace\n",
    "    Wdet = np.zeros_like(image)  # FIXME\n",
    "    Wtr = np.zeros_like(image)  # FIXME\n",
    "\n",
    "    # return Wdet - k * Wtr**2 # k is hard to tune\n",
    "    # return Wdet / Wtr # we would need to filter NaNs\n",
    "    return Wdet / (Wtr + 1)  # 1 seems to be a reasonable value for epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display some bubbles and their Harris response\n",
    "# showing the scale of values may be interesting\n",
    "# TIP: reuse and adapt previous display code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Identify corners among the maximas\n",
    "Now we have computed the \"cornerness map\" of an image, we have to select the best corner candidates.\n",
    "The full process for selecting keypoints (ie coordinates of corners) can be decomposed in:\n",
    "1. compute the Harris corner response map;\n",
    "2. create a mask to select best keypoints and reject the ones which are too close from the border of the image **or of the bubble** (more details below);\n",
    "3. pre-select and sort the candidates based on their response value;\n",
    "4. iteratively select the best keypoints, discarding weaker keypoints which are too close (maximum filter).\n",
    "\n",
    "The masking step is a bit special in our case because our bubbles have an artificial boundary inside the image which can cause keypoints to be detected.\n",
    "We want to reject keypoints which are too close from the bubble boundary to avoid this.\n",
    "To save you time, we provide you with a simple function `bubble2maskeroded` which takes a bubble and returns a mask which removes the border of the bubble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "# mathematical morphology magic: this returns an eroded (shrunk) mask\n",
    "def bubble2maskeroded(img_gray, border=10):\n",
    "    if img_gray.ndim > 2:\n",
    "        raise ValueError(\n",
    "            \"\"\"bubble2maskeroded: img_gray must be a grayscale image.\n",
    "            The image you passed has %d dimensions instead of 2.\n",
    "            Try to convert it to grayscale before passing it to bubble2maskeroded.\n",
    "            \"\"\" % (img_gray.ndim, ))\n",
    "    mask = img_gray > 0\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (border*2,border*2))\n",
    "    mask_er = cv2.erode(mask.astype(np.uint8), \n",
    "                        kernel, \n",
    "                        borderType=cv2.BORDER_CONSTANT, \n",
    "                        borderValue=0)\n",
    "    return mask_er > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "# bubble2maskeroded demo\n",
    "bb_id = 5\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(141)\n",
    "plt.imshow(bubbles_gray[bb_id], cmap='gray')\n",
    "plt.axis('on'); plt.title(\"Bubble\");\n",
    "plt.subplot(142)\n",
    "plt.imshow(bubbles_gray[bb_id] > 0)\n",
    "plt.axis('on'); plt.title(\"Mask\");\n",
    "plt.subplot(143)\n",
    "plt.imshow(bubble2maskeroded(bubbles_gray[bb_id]))\n",
    "plt.axis('on'); plt.title(\"Eroded mask\");\n",
    "plt.subplot(144)\n",
    "plt.imshow((bubbles_gray[bb_id] > 0) & np.logical_not(bubble2maskeroded(bubbles_gray[bb_id])))\n",
    "plt.axis('on'); plt.title(\"Removed border\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Complete the function below to build a complete Harris corner detector.**\n",
    "\n",
    "Tips:\n",
    "- Prepare the debug visualization first to check intermediate results progressively.\n",
    "- Check the mask being created in particular.\n",
    "- Check the documentation of `np.nonzero` and try it separately.\n",
    "- Use `np.argsort` to sort values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete this function\n",
    "def detect_harris_points(image_gray, min_distance=10, threshold=0.1):\n",
    "    \"\"\" detect and return corners from a grayscale image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\n",
    "        \n",
    "        returns a list of (x,y) coordinates of corners.\n",
    "    \"\"\"\n",
    "    # 1. Compute Harris corner response\n",
    "    harrisim = np.zeros_like(image_gray) # FIXME\n",
    "    \n",
    "    # 2. Masking\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = harrisim.max() * threshold\n",
    "    harrisim_mask = np.zeros_like(image_gray, dtype=np.bool) # FIXME\n",
    "    # apply the mask to ignore the bubble contours and image borders\n",
    "    # harrisim_mask &= ... # FIXME\n",
    "\n",
    "    # 3. Candidate pre-selection and sorting\n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_mask.nonzero()\n",
    "    coords = np.transpose(candidates)\n",
    "    #...and their values\n",
    "    candidate_values = np.array([])  # FIXME\n",
    "\n",
    "    #sort candidates\n",
    "    index = np.array([])  # FIXME\n",
    "\n",
    "    # 4. Max filter over neighborhood\n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        pass # FIXME\n",
    "        # if the keypoint can be selected\n",
    "            # select it\n",
    "            # update the mask to prevent neighbors from being selected\n",
    "\n",
    "    return np.array(filtered_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (just run this cell)\n",
    "# Display some bubbles and the detected keypoints\n",
    "num_bb = 5\n",
    "min_distance=25\n",
    "plt.figure(figsize=(8,10))\n",
    "for bb_id in range(num_bb):\n",
    "    bb = bubbles[bb_id]\n",
    "    bb_gray = bubbles_gray[bb_id]\n",
    "    bb_h = compute_harris_response(bb_gray)\n",
    "    filtered_coords = detect_harris_points(bb_gray, \n",
    "                                        min_distance=min_distance)\n",
    "    \n",
    "    plt.subplot(num_bb,3,1+3*bb_id)\n",
    "    plt.imshow(imbgr2rgb(bb))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"$I$: bb_%d\" % bb_id)\n",
    "    \n",
    "    plt.subplot(num_bb,3,2+3*bb_id)\n",
    "    plt.imshow(bb_h)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Harris resp.\")\n",
    "\n",
    "    plt.subplot(num_bb,3,3+3*bb_id)\n",
    "    plt.imshow(bb_gray, cmap='gray')\n",
    "    plt.plot(filtered_coords[:,1], filtered_coords[:,0], 'x', c='r')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Corners\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Description of the area around keypoints\n",
    "This step is actually quite simple here: we will simply store the **raw BGR pixel values** around a given keypoint, and store them as a flat vector.\n",
    "This is the simplest descriptor we could use.\n",
    "This will let us reuse the image comparison technique we saw during the session 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Complete the function below to compute a list of descriptors centered around each keypoint.**\n",
    "\n",
    "Tips:\n",
    "- Check the boundaries of the image (just in case some keypoints are extracted too close from the border).\n",
    "- Check the size of the descriptors to avoid generating descriptors we uneven size.\n",
    "- Display some descriptors for a given bubble.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the function below\n",
    "def compute_descriptors(image_color, filtered_coords, wid=24):\n",
    "    \"\"\" For each point return pixel values around the point\n",
    "        using a neighbourhood of width 2*wid+1. (Assume points are \n",
    "        extracted with min_distance > wid). \n",
    "        \n",
    "        return a list of descriptors (np.array)\n",
    "        \"\"\"\n",
    "    \n",
    "    desc = []\n",
    "    for coords in filtered_coords:\n",
    "        pass  # FIXME\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some display to check the results\n",
    "bb_id = 3\n",
    "num_descr = 5\n",
    "patch_half_size = 12\n",
    "kpts = detect_harris_points(bubbles_gray[bb_id], min_distance=patch_half_size+1)\n",
    "desc = compute_descriptors(bubbles[bb_id], kpts, wid=patch_half_size)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,num_descr+1,1)\n",
    "plt.imshow(bubbles_gray[bb_id], cmap='gray')\n",
    "plt.plot(kpts[:,1], kpts[:,0], 'x', c='r')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Corners\")\n",
    "for ii in range(min(num_descr, len(desc))):\n",
    "    plt.subplot(1,num_descr+1,2+ii)\n",
    "    dside = int(np.sqrt(desc[ii].shape[0]/3)) # recover the patch size\n",
    "    plt.imshow(cv2.cvtColor(desc[ii].reshape((dside, dside, 3)), cv2.COLOR_BGR2RGB))\n",
    "    plt.plot([dside//2], [dside//2], '*', c='r')\n",
    "#     plt.axis('off')\n",
    "    plt.title(\"Descr. %d\" % ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Precompute the keypoints and their descriptors for all the bubbles\n",
    "This will be useful for the next part, to accelerate the computation of the matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Pre-compute all the keypoints and descriptors for all bubbles.**\n",
    "\n",
    "Tips:\n",
    "- Extract descriptors from regions of approximatively 25 per 25 pixels, separated at least by 10 pixels.\n",
    "- Others values may produce different results: you may want to come back here at the end of the session to try different extraction strategies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO precompute keypoints and descriptors for all bubbles using `bubbles` and `bubbles_gray`\n",
    "patch_half_size = 1  # FIXME\n",
    "keypoints = []  # list of keypoints for all bubbles: keypoints[i]: (np.array) keypoints for bubbles_gray[i]\n",
    "descriptors = []  # list of descriptors for all bubbles: descriptors[i]: (list of np.array) desc for bubbles[i]\n",
    "# FIXME\n",
    "print(len(keypoints), len(descriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: do we have bubbles without keypoints?\n",
    "for ii, ki in enumerate(keypoints):\n",
    "    if len(ki) == 0:\n",
    "        plt.figure()\n",
    "        plt.imshow(bubbles_gray[ii], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"b%03d.png\" % (ii+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Save the pre-computed keypoints and descriptors: we will use then in the next part.**\n",
    "\n",
    "Tips:\n",
    "- Save them somewhere on the network to save RAM (if working in EPITA's computers).\n",
    "- Use `np.savez_compressed` or any similar function to save objects.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO save keypoints and descriptors somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job done!\n",
    "Now you're ready to move on to the next stage: [Match keypoints and solve *Twin it!*](practice_02-03_twinit-part2-matching.ipynb)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
